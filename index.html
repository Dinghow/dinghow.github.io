<!DOCTYPE html>

<html><head>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta content="IE=5.0000" http-equiv="X-UA-Compatible">
  <meta name="description" content="Dinghao YANG's home page"> 
  
  <link href="./files/wfdoc.css" rel="stylesheet" type="text/css"> 
  <title>Dinghao YANG's Homepage</title> 
  <link rel="icon" href="./files/favicon.png">
  <meta name="GENERATOR" content="MSHTML 11.00.10570.1001">
</head>


<body> 
  <div id="layout-content" style="margin-top: 25px;">
  <table>
    <tbody>
    <tr>
      <td width="670">
        <div id="toptitle">
        <h1>Dinghao YANG &nbsp; 杨丁豪</h1></div>
        <h3>Senior System Engineer, NVIDIA</h3>
        <br>Hangzhou, China
        <br>
        <br> Email:  
        <a href="mailto:dinghaoy@nvidia.com"> dinghaoy@nvidia.com</a>;
        <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="mailto:dinghowyang@gmail.com">     dinghowyang@gmail.com</a>; 
        <br> Google Scholar:  
        <a href="https://scholar.google.com/citations?user=0V_bdaoAAAAJ&hl=en" target="_blank"> Google Scholar Link</a>
        <br> Github: 
        <a href="https://github.com/Dinghow" target="_blank">https://github.com/Dinghow</a> 
        <br> Personal Blog: 
        <a href="https://dinghow.site/dinghow-blog" target="_blank">https://dinghow.site/dinghow-blog</a> 
        <br><br></p>
      </td>
      <td>
        <img width="360" src="./files/ydh.jpg" border="0">
      </td>
    </tr>
    <tr></tr></tbody>
  </table>
  <div id="layout-content" style="margin-top: 25px;">


  <h2>Biography</h2>
  <p> I am a senior system engineer at NVIDIA, focusing on the training algorithm exploration and framework development for GenAI models, e.g., LLM, Diffusion model. I'm lucky to work with <a href="https://www.linkedin.com/in/jiaxin-cao-2166081b3/" target="_blank">Jiaxin Cao</a>, <a href="https://scholar.google.com/citations?user=gSB8_64AAAAJ&hl=en" target="_blank">Junjie Bai</a> and many other talented geeks. Before that, I worked at <a href="https://www.lepton.ai/" target="_blank">Lepton AI</a>, and the <a href="https://www.alibabacloud.com/en/product/machine-learning" target="_blank">Machine Learning Platform for AI</a>, Alibaba Cloud, majored in the development of LLM inference framework (I used to be a core developer for the <a href="https://www.alibabacloud.com/help/en/pai/user-guide/what-is-bladellm/" target="_blank">inference engine</a> of Qwen series). I received the M.S degree from <a href="https://www.ece.pku.edu.cn/" target="_blank">the School of Electronic and Computer Engineering</a>, Peking University, in 2023, and the B.E. degree from <a href="https://sse.tongji.edu.cn/" target="_blank">the School of Software Engineerning</a>, Tongji University, in 2020. I used to be a research intern at  <a href="https://www.sensetime.com/cn/technology-detail?categoryId=44" target="_blank">Data and Computing Platform</a>, SenseTime Research, during 2020-2022, supervised by <a href="https://scholar.google.com/citations?user=WljXYoYAAAAJ&hl=en&oi=sra" target="_blank">Bin Wang</a> and <a href="https://liweijia.github.io/" target="_blank">Weijia Li</a>.</p>
  <p>My research interests include GenAI Infra, 3D Vision, Physical AI, and World Foundation Model.</p>
  <!-- <p>You can find my Curriculum Vitae <a href="./files/CV_DinghaoYang.pdf">here</a> (may not be updated in time).</p> -->

  <p><b>✨ NOTE</b>: <i>We are looking forward to having elegant researchers and engineers join us. If you want to diving in the training algorithm exploration or framework optimization of Physical AI, feel free to contact me~</i></p>

<h2>Experience</h2>
<ul>
  <li>
    Apr.2025 - Now, <i>Senior System Engineer</i>, <b>NVIDIA</b>
  </li>
  <li>
    Jun.2024 - Apr.2025, <i>Research Engineer (LLM Inference & Training Optimization)</i>, <b>Lepton AI</b>
  </li>

  <li>
   Jul.2023 - May.2024, <i>Algorithm Engineer (LLM Inference Optimization)</i>, <b>Alibaba Cloud</b>
  </li>

  <li>
    Oct.2020 - Jan.2022, <i>Research Intern (Computer Vision)</i>, <b>SenseTime Research</b>
  </li>

  <li>
    Oct.2019 - Jul.2020, <i>Research Intern (3D Vision)</i>, <b>Peng Cheng Lab</b>
  </li>

  <li>
    Sep.2019 - Sep.2019, <i>Research Intern (3D Vision)</i>, <b>Megvii Research</b>
  </li>

</ul>


<h2>Publications</h2>
<h3>Preprint Papers</h3>
<table class="pub_table">
<tbody>
  <tr>
    <td class="pub_td1"><img src="./files/cosmos-predict2_5.png" class="papericon"></td>
    <td class="pub_td2"><b>World Simulation With Video Foundation Models for Physical AI</b>
      <br>NVIDIA (I am a core contributor for the Diffusion RL training framework)
      <br>
      [<a href="https://arxiv.org/abs/2511.00062" target="_blank">PDF</a>]
      [<a href="https://github.com/nvidia-cosmos/cosmos-predict2.5" target="_blank">Code</a>]
    </td>
  </tr>

  <tr>
    <td class="pub_td1"><img src="./files/cosmos-reason1.png" class="papericon"></td>
    <td class="pub_td2"><b>Cosmos-reason1: From physical common sense to embodied reasoning</b>
      <br>NVIDIA (I am a core contributor for the SFT & RL training framework)
      <br>
      [<a href="https://arxiv.org/abs/2503.15558" target="_blank">PDF</a>]
      [<a href="https://github.com/nvidia-cosmos/cosmos-reason1" target="_blank">Code</a>]
    </td>
  </tr>

  <tr>
    <td class="pub_td1"><img src="./files/uim.png" class="papericon"></td>
    <td class="pub_td2"><b>Unified Interactive Image Matting</b>
      <br><u>Dinghao Yang</u>, Bin Wang, Weijia Li, Yiqi Lin, Conghui He
      <br><i>Under Review</i><br>
      [<a href="https://arxiv.org/abs/2205.08324" target="_blank">PDF</a>]
      [<a href="https://github.com/Dinghow/UIM" target="_blank">Code</a>]
    </td>
  </tr>

</tbody>
</table>


<h3>Published Papers</h3>
<table class="pub_table">
<tbody>
  <tr>
    <td class="pub_td1"><img src="./files/pointchd.png" class="papericon"></td>
    <td class="pub_td2"><b>PointCHD: A Point Cloud Benchmark for Congenital Heart Disease Classification and Segmentation</b>
      <br><u>Dinghao Yang</u>, Wei Gao
      <br><i>IEEE Journal Of Biomedical & Health Informatics (<b>JBHI</b>)</i>
      <br>
      [<a href="https://ieeexplore.ieee.org/document/10748410" target="_blank">PDF</a>]
      [<a href="https://github.com/Dinghow/PointCHD" target="_blank">Code</a>]
    </td>
  </tr>

  <tr>
    <td class="pub_td1"><img src="./files/ugbs.png" class="papericon"></td>
    <td class="pub_td2"><b>Exploring the User Guidance for More Accurate Building Segmentation from High-Resolution Remote Sensing Images</b>
      <br><u>Dinghao Yang</u>, Bin Wang, Conghui He, Weijia Li
      <br><i>International Journal of Applied Earth Observation and Geoinformation (<b>JAG</b>)</i><br>
      [<a href="https://www.sciencedirect.com/science/article/pii/S1569843223004338" target="_blank">PDF</a>]
      [<a href="https://github.com/StephenDHYang/UGBS-pytorch" target="_blank">Code</a>]
    </td>
  </tr>

  <tr>
    <td class="pub_td1"><img src="./files/pointmanifold.png" class="papericon"></td>
    <td class="pub_td2"><b>Exploiting Manifold Feature Representation for Efficient Classification of 3D Point Clouds</b>
      <br><u>Dinghao Yang</u>, Wei Gao, Ge Li, Hui Yuan, Junhui Hou, Sam Kwong
      <br><i>ACM Transactions on Multimedia Computing, Communications and Applications (<b>TOMM</b>)</i><br>
      [<a href="https://dl.acm.org/doi/pdf/10.1145/3539611" target="_blank">PDF</a>]
      [<a href="https://openi.pcl.ac.cn/dengy02/PointManifold_dy" target="_blank">Code</a>]
    </td>
  </tr>

  </tbody>
</table>

<h2>Projects</h2>
<table class="pub_table">
<tbody>
  <tr>
    <td class="pub_td1"><img src="./files/echo.svg" class="papericon"></td>
    <td class="pub_td2"><b>Cosmos-RL</b>
      <br>Cosmos-RL is a flexible and scalable Reinforcement Learning framework specialized for Physical AI applications.
      I am responsible for the development of the framework, including the design of the training pipeline and the implementation of key algorithms.
      [<a href="https://github.com/nvidia-cosmos/cosmos-rl" target="_blank">Code</a>]
    </td>
  </tr>

  <tr>
    <td class="pub_td1"><img src="./files/bladellm.svg" class="papericon"></td>
    <td class="pub_td2"><b>BladeLLM</b>
      <br>BladeLLM is a high-performance LLM inference engine of Alibaba Cloud, used for the deployment of Qwen series.
      I am responsible for the modeling of LLM models, performance optimization, interface development and triton kernel development.
      <br>
      <br>
      [<a href="https://www.alibabacloud.com/help/en/pai/user-guide/what-is-bladellm/" target="_blank">Introduction</a>]
    </td>
  </tr>

  <tr>
    <td class="pub_td1"><img src="./files/labelbee.png" class="papericon"></td>
    <td class="pub_td2"><b>Intelligent Annotation for SenseBee</b>
      <br>I am principally responsible for the interactive data annotation algorithms for SenseBee,
      the data platform for SenseTime AI research. We propose and deploy deep learning-based
      algorithms to accelerate manual data annotations (i.e. image segmentation, image matting,
      3D object detection).
      <br>
      [<a href="https://github.com/open-mmlab/labelbee-client" target="_blank">Code</a>]
    </td>
  </tr>

  <tr>
    <td class="pub_td1"><img src="./files/openpointcloud.png" class="papericon"></td>
    <td class="pub_td2"><b>OpenPointCloud</b>
      <br>I participate in OpenPointCloud, an open-source algorithm library of deep learning-based point cloud compression & processing, mainly contrbute in the manifold learning-based point cloud representation learning method.
      <br>
      [<a href="https://openi.pcl.ac.cn/OpenPointCloud/OpenPointCloud" target="_blank">Code</a>]
    </td>
  </tr>

</tbody>
</table>


<h2>Awards</h2>
<ul>
    <li>
    Award for Scientific Research, Peking University. 2022.
  </li>
  <li>
    <b>2<sup>nd</sup></b> place at Streaming Detection Challenge, Full Stack Track! (<b>CVPR 2021</b> Workshop)
  </li>
  <li>
    Excellent graduate of Shanghai. 2020.
  </li>
  <li>
    Shanghai Scholarship. 2019.
  </li>
  <li>
    Excellent Leader of Microsoft Student Club, MSRA. 2018.
  </li>
</ul>

<h2>Academic Activities</h2>
<ul>
    <li>
      Journal reviewer: TCSVT
  </li>
  <li>
    Conference reviewer: ACM MM 2022, CVPR 2022, ECCV 2022, ICCVM 2023, ICDIP 2022, IJCAI 2022
  </li>
</ul>

<p align="center">
<a href="https://clustrmaps.com/site/1ao35"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=U0oQ0PrlLrKGWvISfxXJmGognyTaT4s8OO6nyv5a4tw&cl=ffffff" /></a>
<br>

</p>

</div>
</div>

</body></html>
